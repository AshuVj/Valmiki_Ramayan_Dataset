# ğŸ› ï¸ Preprocessing Notes â€“ Valmiki Ramayana Dataset

## ğŸ“Œ Overview
This document explains the preprocessing steps applied to **Valmiki Ramayana Dataset**, including:
* **Data Collection & Sources**
* **Cleaning & Formatting**
* **Handling Merged Shlokas & Missing Values**
* **Challenges & Future Work**

## ğŸ” 1. Data Collection & Sources
The dataset was **compiled from multiple online sources**, structured for machine readability.

### **Primary Data Sources:**
* ğŸ”— **GitaSuperset** â€“ Scraped Sanskrit shlokas, translations, and metadata
* ğŸ”— **IIT Kanpur Sanskrit Repository** â€“ Used as reference for transliteration corrections
* ğŸ“š **M.N. Dutt's English Translation (1891-1894)** â€“ Included for validation

## ğŸ§¹ 2. Data Cleaning & Formatting
### **Standardization Applied:**
âœ… **Converted Sanskrit text to UTF-8 encoding** for proper rendering  
âœ… **Removed extra spaces & special characters** from extracted text  
âœ… **Ensured proper JSON formatting** for structured storage  
âœ… **Normalized transliteration using IAST (International Alphabet of Sanskrit Transliteration)**

## ğŸ›‘ 3. Handling Merged Shlokas
### ğŸ” **Issue:**
* Some shlokas were merged due to **OCR errors or source formatting**
* Example of merged shloka:
```
"shloka_text": "à¤¤à¤®à¥‡à¤µà¤‚ à¤—à¥à¤£à¤¸à¤®à¥à¤ªà¤¨à¥à¤¨à¤‚ à¤°à¤¾à¤®à¤‚ à¤¸à¤¤à¥à¤¯à¤ªà¤°à¤¾à¤•à¥à¤°à¤®à¤®à¥à¥¤à¥¤1.1.19à¥¤à¥¤ à¤œà¥à¤¯à¥‡à¤·à¥à¤ à¤‚ à¤¶à¥à¤°à¥‡à¤·à¥à¤ à¤—à¥à¤£à¥ˆà¤°à¥à¤¯à¥à¤•à¥à¤¤à¤‚ à¤ªà¥à¤°à¤¿à¤¯à¤‚ à¤¦à¤¶à¤°à¤¥à¤¸à¥à¤¸à¥à¤¤à¤®à¥à¥¤à¥¤"
```
* This caused misalignment in translation & explanation fields

### **Solution Implemented:**
âœ”ï¸ **Detection:** A script was written to identify merged shlokas based on **duplicate numbering patterns (e.g., 1.1.19, 1.1.20 appearing together)**  
âœ”ï¸ **Manual Review:** Detected entries were flagged for **manual verification & correction**  
âœ”ï¸ **Future Plan:** AI-based segmentation might be explored

## ğŸ” 4. Handling Missing Values (Null Entries)
### ğŸ” **Issue:**
* Some **translations, explanations, and transliterations were missing** due to incomplete data sources
* Example:
```json
    {
        "kanda": "Uttara Kanda",
        "sarga": 18,
        "shloka": 20,
        "shloka_text": "à¤¤à¤¤à¤¸à¥à¤¤à¤‚ à¤¨à¤¿à¤°à¥à¤œà¤¿à¤¤à¤‚ à¤®à¤¤à¥à¤µà¤¾ à¤˜à¥‹à¤·à¤¯à¤¾à¤®à¤¾à¤¸ à¤µà¥ˆ à¤¶à¥à¤•à¤ƒ à¥¤ à¤°à¤¾à¤µà¤£à¥‹ à¤œà¤¯à¤¤à¥€à¤¤à¥à¤¯à¥à¤šà¥à¤šà¥ˆà¤°à¥à¤¹à¤°à¥à¤·à¤¾à¤¨à¥à¤¨à¤¾à¤¦à¤‚ à¤µà¤¿à¤®à¥à¤•à¥à¤¤à¤µà¤¾à¤¨à¥ à¥¤à¥¤ 7.18.20 à¥¤à¥¤",
        "transliteration": "tatastaá¹ƒ nirjitaá¹ƒ matvÄ ghoá¹£ayÄmÄsa vai Å›ukaá¸¥ | rÄvaá¹‡o jayatÄ«tyuccairhará¹£ÄnnÄdaá¹ƒ vimuktavÄn || 7.18.20 ||",
        "translation": null,
        "explanation": null,
        "comments": null
    }
```

### **Solution Implemented:**
âœ”ï¸ **Flagged Missing Entries:** Entries with `null` values were marked for further improvement  
âœ”ï¸ **Cross-referenced other sources** (GitaPress, IITK) to manually fill gaps **where possible**  
âœ”ï¸ **Future Plan:** AI-based translation (using **IndicBERT / MuRIL**) to fill gaps **automatically**

## âš ï¸ 5. Known Challenges & Future Work
ğŸ”¸ **Shloka Segmentation**: AI-based segmentation might be used for better handling of **merged texts**  
ğŸ”¸ **Translation Completion**: Missing translations may be auto-filled with **AI models trained on Sanskrit texts**  
ğŸ”¸ **Validation with Scholars**: Cross-verification with Sanskrit scholars can **improve accuracy**

## ğŸ”— 6. Contribution Guide
ğŸ‘¨â€ğŸ’» If you want to **help improve the dataset**, follow these steps:

1ï¸âƒ£ **Identify errors/missing translations** â€“ Open an **issue** on GitHub  
2ï¸âƒ£ **Suggest better corrections** â€“ Submit a **Pull Request** with proper references  
3ï¸âƒ£ **Provide additional scholarly sources** â€“ Help refine **translations & explanations**

## ğŸ•‰ï¸ Final Thought
*"May this dataset serve as a foundation for Sanskrit AI research & preservation of ancient knowledge."*

ğŸ™ **Jai Shri Ram!** ğŸš€